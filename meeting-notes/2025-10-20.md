# 회의록 - 코드 유사도 판별 프로젝트

**날짜**: 2025년 10월 20일 (일)  
**팀명**: I'm fine tuning

---

## 회의 주제
데이터 전처리 및 토크나이저 최종 결정

---

## 마감 일정
- **오늘까지**: 데이터 전처리 방식 최종 결정
- **목적**: 모델 학습 후 테스트 준비

---

## 프로젝트 프로세스
```
Pretrain → Fine-tuning
```

---

## 역할 분담

| 담당자 | 역할 |
|--------|------|
| 조병률님, 오정탁님 | 데이터 구조 |
| 이서율님, 황호성님 | 모델 2가지 |
| 이홍기님 | 파인튜닝 |

---

## 최종 결정 사항

### 1. 데이터 전처리
- **중복 제거만 수행**
- 복잡한 익명화, 정규화 과정은 적용하지 않음

### 2. 토크나이저 (검토 중)

#### 옵션 1: WordPiece
- BERT, CodeBERT에서 사용
- 서브워드 분할 방식
- 기본 스페셜 토큰만 사용

#### 옵션 2: BPE (Byte Pair Encoding)
- GPT, RoBERTa에서 사용
- 빈도 기반 서브워드 병합
- 기본 스페셜 토큰만 사용

### 3. 스페셜 토큰
- **각 토크나이저의 기본 제공 토큰만 사용**
- 커스텀 토큰(`<NL>`, `<NUM>`, `<STR>`, `<INDENT>` 등) 추가하지 않음

---

## 다음 단계
- [ ] WordPiece vs BPE 최종 선택
- [ ] 중복 제거 로직 구현
- [ ] 선택한 토크나이저로 데이터 전처리 파이프라인 구축

---

**작성일**: 2025년 10월 20일  
**작성자**: I'm fine tuning 팀